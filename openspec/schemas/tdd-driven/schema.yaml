name: tdd-driven
version: 1
description: TDD workflow — proposal → specs → design → tests (red) → tasks (green) → apply (branch + implement + PR)
artifacts:
  - id: proposal
    generates: proposal.md
    description: Initial proposal document outlining the change
    template: proposal.md
    instruction: |
      Create the proposal document that establishes WHY this change is needed.

      Sections:
      - **Why**: 1-2 sentences on the problem or opportunity. What problem does this solve? Why now?
      - **What Changes**: Bullet list of changes. Be specific about new capabilities, modifications, or removals. Mark breaking changes with **BREAKING**.
      - **Capabilities**: Identify which specs will be created or modified:
        - **New Capabilities**: List capabilities being introduced. Each becomes a new `specs/<name>/spec.md`. Use kebab-case names (e.g., `user-auth`, `data-export`).
        - **Modified Capabilities**: List existing capabilities whose REQUIREMENTS are changing. Only include if spec-level behavior changes (not just implementation details). Each needs a delta spec file. Check `openspec/specs/` for existing spec names. Leave empty if no requirement changes.
      - **Impact**: Affected code, APIs, dependencies, or systems.

      IMPORTANT: The Capabilities section is critical. It creates the contract between
      proposal and specs phases. Research existing specs before filling this in.
      Each capability listed here will need a corresponding spec file.

      Keep it concise (1-2 pages). Focus on the "why" not the "how" -
      implementation details belong in design.md.

      This is the foundation - specs, design, and tasks all build on this.
    requires: []

  - id: specs
    generates: "specs/**/*.md"
    description: Detailed specifications for the change
    template: spec.md
    instruction: |
      Create specification files that define WHAT the system should do.

      Create one spec file per capability listed in the proposal's Capabilities section.
      - New capabilities: use the exact kebab-case name from the proposal (specs/<capability>/spec.md).
      - Modified capabilities: use the existing spec folder name from openspec/specs/<capability>/ when creating the delta spec at specs/<capability>/spec.md.

      Delta operations (use ## headers):
      - **ADDED Requirements**: New capabilities
      - **MODIFIED Requirements**: Changed behavior - MUST include full updated content
      - **REMOVED Requirements**: Deprecated features - MUST include **Reason** and **Migration**
      - **RENAMED Requirements**: Name changes only - use FROM:/TO: format

      Format requirements:
      - Each requirement: `### Requirement: <name>` followed by description
      - Use SHALL/MUST for normative requirements (avoid should/may)
      - Each scenario: `#### Scenario: <name>` with WHEN/THEN format
      - **CRITICAL**: Scenarios MUST use exactly 4 hashtags (`####`). Using 3 hashtags or bullets will fail silently.
      - Every requirement MUST have at least one scenario.

      MODIFIED requirements workflow:
      1. Locate the existing requirement in openspec/specs/<capability>/spec.md
      2. Copy the ENTIRE requirement block (from `### Requirement:` through all scenarios)
      3. Paste under `## MODIFIED Requirements` and edit to reflect new behavior
      4. Ensure header text matches exactly (whitespace-insensitive)

      Common pitfall: Using MODIFIED with partial content loses detail at archive time.
      If adding new concerns without changing existing behavior, use ADDED instead.

      Specs should be testable - each scenario maps directly to a test case.
    requires:
      - proposal

  - id: design
    generates: design.md
    description: Technical design document with implementation details
    template: design.md
    instruction: |
      Create the design document that explains HOW to implement the change.

      When to include design.md (create only if any apply):
      - Cross-cutting change (multiple services/modules) or new architectural pattern
      - New external dependency or significant data model changes
      - Security, performance, or migration complexity
      - Ambiguity that benefits from technical decisions before coding

      Sections:
      - **Context**: Background, current state, constraints, stakeholders
      - **Goals / Non-Goals**: What this design achieves and explicitly excludes
      - **Decisions**: Key technical choices with rationale (why X over Y?). Include alternatives considered for each decision.
      - **Risks / Trade-offs**: Known limitations, things that could go wrong. Format: [Risk] → Mitigation
      - **Migration Plan**: Steps to deploy, rollback strategy (if applicable)
      - **Open Questions**: Outstanding decisions or unknowns to resolve

      Focus on architecture and approach, not line-by-line implementation.
      Reference the proposal for motivation and specs for requirements.

      Good design docs explain the "why" behind technical decisions.
    requires:
      - proposal

  - id: tests
    generates: tests.md
    description: "TDD Red phase: write failing tests that define expected behavior"
    template: tests.md
    instruction: |
      Create the test plan following TDD Red phase: define tests that MUST FAIL initially.

      This is the RED phase of TDD (Red → Green → Refactor). Each spec scenario
      maps to one or more test cases. Write tests BEFORE any implementation exists.

      Guidelines:
      - **One test per scenario** from the specs, minimum. Add edge cases as needed.
      - Group tests by capability or feature area using ## numbered headings.
      - Each test MUST be a checkbox: `- [ ] X.Y Test description`
      - Write test descriptions as behavior assertions: "it should...", "it returns...", "it rejects..."
      - Include the test type: `[Feature]`, `[Unit]`, `[Browser]`
      - Reference the spec scenario being tested.

      Test structure for this project (Laravel + Pest):
      - Feature tests: `tests/Feature/` — test HTTP endpoints, Livewire components, full request cycle
      - Unit tests: `tests/Unit/` — test services, value objects, isolated logic
      - Browser tests: `tests/Browser/` — test UI flows with Playwright (Pest browser plugin)

      Example:
      ```
      ## 1. User Authentication

      - [ ] 1.1 [Feature] User can register with valid email and password (Scenario: Successful registration)
      - [ ] 1.2 [Feature] Registration fails with duplicate email (Scenario: Duplicate email rejection)
      - [ ] 1.3 [Unit] Password must meet strength requirements (Scenario: Weak password rejection)
      - [ ] 1.4 [Browser] Registration form shows validation errors inline (Scenario: Form validation UX)
      ```

      After writing this file, the apply phase will:
      1. Create the actual test files with Pest
      2. Run them to confirm they ALL FAIL (red phase)
      3. Only then proceed to implementation (green phase)

      IMPORTANT: Do NOT include implementation tasks here. Only tests.
      Implementation goes in tasks.md (the next artifact).
    requires:
      - specs
      - design

  - id: tasks
    generates: tasks.md
    description: "TDD Green phase: implementation tasks to make failing tests pass"
    template: tasks.md
    instruction: |
      Create the implementation task list — the GREEN phase of TDD.

      At this point, failing tests already exist (from the tests artifact).
      Every task here should move one or more tests from RED to GREEN.

      Guidelines:
      - Group related tasks under ## numbered headings.
      - Each task MUST be a checkbox: `- [ ] X.Y Task description`
      - Tasks should be small enough to complete in one session.
      - Order tasks by dependency (what must be done first?).
      - After each task, specify which tests should now pass.
      - Include a final refactor step per group if applicable.

      Structure:
      ```
      ## 1. Database & Models

      - [ ] 1.1 Create migration for X table
      - [ ] 1.2 Create X model with relationships and factory
            → Tests passing: 1.1, 1.2

      ## 2. Service Layer

      - [ ] 2.1 Implement XService with Y method
      - [ ] 2.2 Add error handling for edge cases
            → Tests passing: 2.1, 2.2, 2.3

      ## 3. Refactor & Cleanup

      - [ ] 3.1 Extract shared logic into trait/concern
      - [ ] 3.2 Run full test suite, verify all green
      - [ ] 3.3 Run `composer lint` (Pint + Rector + Prettier)
      ```

      Reference specs for what needs to be built, design for how, and tests
      for what must pass. Each task should be verifiable — run the associated
      tests to know when it's done.
    requires:
      - tests
      - design

apply:
  requires: [tasks]
  tracks: tasks.md
  instruction: |
    ## Apply: Branch → Red → Green → PR

    Follow this workflow strictly:

    ### 1. Branch
    Create a feature branch for this change:
    ```bash
    git checkout -b change/<change-id>
    ```

    ### 2. Red Phase (from tests.md)
    - Read `tests.md` and create all test files using Pest.
    - Run the tests: `php artisan test --compact`
    - **Verify they ALL FAIL.** If any pass, the test is not testing new behavior — fix it.
    - Commit: `git commit -m "test: add failing tests for <change-id>"`

    ### 3. Green Phase (from tasks.md)
    - Work through `tasks.md` sequentially.
    - After each task group, run the associated tests.
    - Mark tasks as `[x]` when their tests pass.
    - Do NOT move to the next group until current tests are green.
    - Commit after each group: `git commit -m "feat: <description>"`

    ### 4. Refactor Phase
    - Run full test suite: `composer test`
    - Run linting: `composer lint`
    - Fix any issues without breaking tests.
    - Commit: `git commit -m "refactor: cleanup <change-id>"`

    ### 5. Pull Request
    - Push the branch: `git push origin change/<change-id>`
    - Create PR with summary from proposal.md
    - Link to the change directory for reviewers

    ### Pause Rules
    - Pause if any test fails unexpectedly after going green.
    - Pause if you need to modify a spec (go back to specs artifact).
    - Pause if a dependency or blocker is discovered.
